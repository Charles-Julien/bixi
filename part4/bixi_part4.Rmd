---
title: "Part 4: Linear Mixed Models"
author: "Charles Julien, Chike Odenigbo, Atul Sharma, Gabriel Jobert"
date: "10/20/2023"
geometry: "left=2cm,right=2cm,top=1cm,bottom=1.2cm"
output:
  pdf_document:
    toc: true
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message = FALSE, warning=FALSE, include = FALSE, echo=FALSE}
# Import (The fewer the better)
library(nlme)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(leaflet)
library(gridExtra)
library(broom)
library(stats)
library(car)
library(janitor)
library(tibble)

library(nlme)
library(lmtest)
library(lme4)
#install.packages("sf")
library(sf)
#install.packages("lmerTest")
library(lmerTest)
```


```{r load_data, include=FALSE}
# Data loading

# Set working directory to file location

setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
df_raw = read.csv("./../src/bixi10.csv")
df_station = read.csv("./../src/2021_stations.csv")


bixi_stations_sf <- st_as_sf(df_station, coords = c("longitude", "latitude"), crs = 4326)

districts <- st_read("./../src/data_district.geojson")

crs_bixi_stations <- st_crs(bixi_stations_sf)
crs_districts <- st_crs(districts)

# Print CRS for inspection
print(crs_bixi_stations)
print(crs_districts)

# If the CRS do not match, transform one of them
# For example, if you want to transform the CRS of bixi_stations_sf to match districts:
if (crs_bixi_stations != crs_districts) {
  bixi_stations_sf <- st_transform(bixi_stations_sf, crs_districts)
}

# After ensuring both dataframes have the same CRS, perform the spatial join
stations_with_district <- st_join(bixi_stations_sf, districts)

# Perform a spatial join
# Add the district name as a new column
df_station$district <- stations_with_district$NOM



ids_to_update <- c('527', '528', '529', '530', '531', '703', '704', '705', '706', '856', '862', '944', '945', '1060', '1065', '1085', '1086', '1126', '1136') 
districts_to_assign <- c('Longueuil', 'Longueuil', 'Longueuil', 'Longueuil', 'Longueuil', 'Laval', 'Laval', 'Laval', 'Laval', 'Ville-Marie', 'Longueuil', 'Laval', 'Laval', 'Laval', 'Laval', 'Laval', 'Laval', 'Laval', 'Laval') 

for (i in seq_along(ids_to_update)) {
  row_index <- which(df_station$pk == ids_to_update[i])
  df_station$district[row_index] <- districts_to_assign[i]
}

df_station$district = as.factor(df_station$district)

df_main = left_join(df_raw,df_station,by = c("station"="pk"))

```

```{r echo=FALSE}
# Data preparation and feature engineering


# Note: Correlation between rev and dur is very high 0.994467
df_main$rev[is.na(df_main$rev)] <- df_main$n_tot[is.na(df_main$rev)] * 1.25 + df_main$dur[is.na(df_main$rev)] * 15


df_main <- df_main %>% dplyr::mutate(
              holiday = factor(holiday),
              mem = factor(mem),
              mm = factor(mm),
              station = factor(station),
              
              wday_ordered = factor(wday, levels = c("Monday", "Tuesday", "Wednesday",  "Thursday", "Friday", "Saturday", "Sunday"),ordered = TRUE),
              season = ifelse((mm %in% c(12,1,2)), 'Winter',
                       ifelse((mm %in% c(3,4,5)), 'Spring',
                       ifelse((mm %in% c(6,7,8)), 'Summer',
                       ifelse((mm %in% c(9,10,11)), 'Fall','No Season')))),
              
              rain_ind = factor(ifelse((rain != 0), 'Rain', 'NoRain')),
              

              # Compared to Parc Lafontaine 
              cardinality = factor(
              ifelse(latitude > 45.5271 & longitude > -73.5705, 'North-East',
                ifelse(latitude > 45.5271 & longitude <= -73.5705, 'North-West',
                  ifelse(latitude <= 45.5271 & longitude > -73.5705, 'South-East',
                         'South-West')
                                    )
                                  )
                                ),
              
              
              Metro_ind = factor(ifelse(grepl("Métro", name),1,0)),
              
              am_pm_ind = ifelse(n_AM>=n_PM, 'AM','PM'),
              
              wknd_ind = factor(ifelse((wday %in% c("Sunday","Saturday")), 'Weekend'
                        ,'Weekday')),
                

              long_wknd_ind = factor(ifelse((wday %in% c("Sunday","Saturday")),'Weekend'
              ,ifelse((wday %in% c("Friday","Monday") & holiday=='1'),'Long Weekend','Weekday'))),
              
              percent_AM = n_AM/n_tot,
              percent_PM = n_PM/n_tot,
        
              year = 2021 ,
              
              date = as.Date(paste(year,mm,dd,sep="/")),
              
              week_num = as.numeric(strftime(date, format = "%V")))
 



df_main =df_main[order(df_main$date),]


```



# Introduction

**Enhancing Urban Mobility Through Advanced Analytics: Unraveling
Patterns in BIXI Data**

BIXI, the public cycling service, has emerged as a pivotal player in
urban transportation, offering an accessible and eco-friendly mode of
transportation that has reshaped urban mobility. Our commitment to
understanding and improving urban transportation systems has led our
consultant team to conduct an extensive analysis of BIXI's operational
data.

This report builds upon our previous exploration of BIXI's data,
focusing on the application of linear mixed models to uncover nuanced
insights. Our objective is to provide a comprehensive analysis of
factors influencing BIXI's performance, extending our investigation to
three specific research questions (RQs). These RQs delve into the impact
of meteorological conditions, temporal patterns, and user
classifications on BIXI's revenue generation.

In this journey, we leverage advanced statistical techniques,
particularly linear mixed models, to unravel complex relationships
within the dataset. R, a powerful statistical tool, serves as our
primary instrument for data analysis and modeling. Our findings aim to
not only deepen the understanding of BIXI's dynamics but also provide
actionable insights for enhancing operational efficiency.

The central RQs explored in this report include the assessment of the
seasonal impact on revenue, understanding the temporal patterns
affecting trip duration, and examining the influence of user
classifications on BIXI's performance. By addressing these questions, we
aim to contribute valuable insights that can inform strategic
decision-making for BIXI and serve as a reference for urban planners,
researchers, and policymakers committed to creating sustainable and
enjoyable urban environments.

The subsequent sections of this report will delve into the methodologies
employed, share the findings derived from our analysis, and offer
recommendations to support BIXI in continually improving its services.

# Business/Research questions

-   Research Question 1: How do seasonal factors impact trip revenue for
    BIXI Montréal?
-   Research Question 2: How do daily and weekly patterns impact trip
    durations for BIXI Montréal?
-   Research Question 3: What variables impact the average bixi trip
    duration?


Before jumping in, let's perform a quick exploration of our data.
```{r}
df_explore = df_main %>%
  group_by(station, mem) %>%
  summarize(n = n())
  
summary(df_explore$n)
```
The unique identifier of a line in our dataset is a combination of the station, the date and the membership status. On average, a station for a given membership status appears 6 times in our dataset.

# Research Question 1: How do seasonal factors impact trip revenue for BIXI Montréal?

ADD INTERACTION TERM **Objective of Analysis:** This regression model is
examining the impact of the month (`mm`), average daily temperature
(`temp`), and total amount of rainfall (`rain`) and membershipt (`mem`)
on the revenue (`rev`) generated by trips leaving from a specified
station.

## Model Linear regression

```{r Seasonal_effect_revenue, echo=FALSE}
seasonal_effect_rev_model <- lm(rev ~ mm + temp + rain + mem, data = df_main)
summary(seasonal_effect_rev_model)
```

## Model Linear Mixed model (ATUL)

Comment: compound symmetric correlation structure is not ideal for time
series if I am not mistaken

```{r}
seasonal_effect_rev_gls <- gls(rev ~ temp + rain + mm + mem, correlation = corCompSymm(form = ~ 1 | station), data = df_main)

# Display model summary
summary(seasonal_effect_rev_gls)
```

```{r}
# CHIKE: Note that using compound symmetric gives the same covariance to each observation
cov.matrix = getVarCov(seasonal_effect_rev_gls,individual = 1)
cov2cor(cov.matrix)
```

```{r}
coefficients_and_pvalues <- coef(summary(seasonal_effect_rev_gls))
print(coefficients_and_pvalues)

# Extract residuals from the GLS model
residuals_gls <- residuals(seasonal_effect_rev_gls)

# Create a Normal Q-Q plot
qqnorm(residuals_gls, main = "Normal Q-Q Plot of Residuals")
qqline(residuals_gls)
```

##Strength of the model

The Normal Q-Q plot provides valuable insights into the distribution of
residuals in the BIXI data model. The near-perfect alignment of
residuals with the reference line from -4 to +2 suggests that a
substantial portion of the residuals adheres to a normal distribution.
However, the major upward deviation observed from +2 to +4 indicates the
presence of extreme positive residuals that do not align with the
expected normal distribution. This discrepancy highlights a limitation
in the model, signaling the existence of outliers or influential
observations that could significantly impact the model's accuracy. These
outliers may be indicative of unaccounted-for factors or unexpected
events that contribute to revenue variations beyond the model's current
specifications. Addressing this limitation may involve further
exploration of the data to identify the sources of these extreme
residuals, potential model refinements, or the consideration of
alternative modeling approaches to better capture the underlying
patterns in the BIXI revenue data.

## Interpretation

**Intercept (14.27)**: The expected revenue in April is, on average,
14.27 \$ when temperature (temp) is zero, there is not rain). It is
difficult to interpret at practically, temperature would not be zero in
April.

**Temperature (0.15)**: A one-unit increase in temperature is associated
with a 0.15 \$ increase, on average, in revenue, keeping other variables
constant. Higher temperatures are positively correlated with increased
revenue.

**Rainfall (-0.22)**: Rainfall leads a 0.22 unit decrease in revenue
keeping other variables constant. Higher rainfall is negatively
correlated with revenue, suggesting potential negative effects on Bixi
usage.

**May (mm5 - 2.44)**: Revenue is expected to increase by 2.44 \$, on
average, in May compared to April (reference month) keeping other
variables constant. May is associated with higher revenue compared to
April.

**June (mm6 - 6.99)**: Revenue is expected to increase by 6.99 \$, on
average, in June compared to April keeping other variables constant.
June has a significant positive impact on revenue.

**July (mm7 - 13.73)**: Revenue is expected to increase by 13.73 \$, on
average, in July compared to April keeping other variables constant.
Interpretation: July has the most significant positive impact on revenue
among the months.

**August (mm8 - 14.69)**: Revenue is expected to increase by 14.69 \$,
on average, in August compared to April keeping other variables
constant. Interpretation: August has a substantial positive impact on
revenue.

**September (mm9 - 15.82)**: Revenue is expected to increase by 15.82
\$, on average, in September compared to April keeping other variables
constant. September has substantial positive impact on revenue.

**October (mm10 - 9.19)**: Revenue is expected to increase by 9.19 \$,
on average, in October compared to April keeping other variables
constant. Interpretation: October has a positive impact on revenue.

**November (mm11 - 3.29)**: Revenue is expected to increase by 3.29 \$,
on average, in November compared to April keeping other variables
constant. November has a modest positive impact on revenue.

##Business Implications:

**Temperature**: Bixi can capitalize on warmer temperatures by promoting
increased ridership during favorable weather conditions.

**Rainfall**: Strategies to mitigate the negative impact of rainfall on
revenue may include targeted marketing during rainy periods or offering
promotions to incentivize usage.

**Seasonal Variation**: Understanding the seasonal variation allows Bixi
to allocate resources effectively, focusing on peak months like July,
August, and September for marketing and service enhancements.

**Month-specific Strategies**: Tailoring marketing campaigns or
promotional offers based on the impact of each month on revenue can
optimize Bixi's overall financial performance.

**Planning and Resource Allocation**: Knowledge of specific months with
higher revenue can guide resource allocation, such as increasing bike
availability and marketing efforts during peak months.

**Operational Adjustments**: Bixi can make operational adjustments, such
as increasing staff or bikes, during months with the most significant
positive impact on revenue.

## Verification of Assumptions

NEED A MORE COMPLETE ASSUPTION VALIDATION \### Normality of residuals

```{r echo=FALSE}
# par(mfrow=c(1,2), pin=c(2,2))  # 1 row, 2 columns
# seasonal_effect_rev_residual_qqplot = qqnorm(seasonal_effect_rev_model$residuals)
# qqline(seasonal_effect_rev_model$residuals)
# seasonal_effect_rev_residual_hist = hist(seasonal_effect_rev_model$residuals, main="Histogram of Residuals", xlab="Residuals")

```

1.  **Histogram of Residuals**: 

2.  **Normal Q-Q Plot**: 

**Overall Interpretation**: 

## Research Question 1: Autoregressive Structure (CHIKE)

Linear Mixed Models (LMMs) - Model Comparisons (joshuawiley.com)

```{r}
#library(ggplot2)
# tous / all id
#ggplot(data = df_main, aes(x = week_num, y = rev_imputed, group = station)) +
#geom_line(alpha = 0.2) + scale_x_continuous(expand = c(0,
#0), limits = c(1, 5))

```


```{r}
seasonal_effect_rev.ar <- gls(rev ~ temp + rain + mm + mem, correlation = corAR1(form = ~ 1 | station), data = df_main)

# Display model summary
#summary(seasonal_effect_rev.ar)
```


```{r}
getVarCov(seasonal_effect_rev.ar,individual = 1)
```
As expected with an auto-regressive correlation structure, the further
back the time period, the lower the correlation.

It is important to note that the time distance between these observations is not constant, in some cases, it can even be null. For example, when a station is observed on the same day for members and non-members. Having a covariance that considers the time between observation would be the best. (ARH1)

## Research Question 1: Random Intercept (CHIKE)

```{r}
#df_main
seasonal_effect_rev.rand_int <- lme(rev ~ temp + rain + mm + mem, random = ~ 1 | station, data = df_main)

# Display model summary
#summary(seasonal_effect_rev.rand_int)
```

```{r}
# Expected to be True comparing fixed effects coefficients between base model and random effects model
isTRUE(all.equal(coef(seasonal_effect_rev_model), fixef(seasonal_effect_rev.rand_int)))
```

```{r}
getVarCov(seasonal_effect_rev.rand_int, type = "random.effects")
```

```{r}
getVarCov(seasonal_effect_rev.rand_int, individual = 1, type = "conditional")
```
This is the same as looking at the variance of the error term

```{r}
seasonal_effect_rev.ar_rand_int <- lme(rev ~ temp + rain + mm + mem, random = ~1 |
station, correlation = corAR1(form = ~1 | station), data = df_main)
#summary(seasonal_effect_rev.ar_rand_int)

```

```{r}
getVarCov(seasonal_effect_rev.ar_rand_int, type = "random.effects")
```

```{r}
AIC(seasonal_effect_rev.ar, seasonal_effect_rev.rand_int, seasonal_effect_rev.ar_rand_int )
```

## Research Question 1: Random Slope (CHIKE)

```{r}
#Doesnt make sense in this context to use random effects on the coefficient for #temperature because temperature across montreal should be highly similar
#Using rain random effect does not work
seasonal_effect_rev.rand_coef <- lme(rev ~ temp + rain + mm + mem, random = ~1 + temp |
station, data = df_main)
#summary(seasonal_effect_rev.rand_coef)
```



```{r}
summary_season_rev.base = tidy(seasonal_effect_rev_model)
colnames(summary_season_rev.base) <- c('Covariates','Value','Std.Error','t-value','p-value')
summary_season_rev.base$type = 'Base'
#summary_season_rev.base
```


```{r}
summary_season_rev.ar = as.data.frame(summary(seasonal_effect_rev.ar)$tTable)
summary_season_rev.ar$type = 'Autoregressive'
#summary_season_rev.ar[,c('DF')] <- NA
summary_season_rev.ar = tibble::rownames_to_column(summary_season_rev.ar, "Covariates")

summary_season_rev.rand_int = as.data.frame(summary(seasonal_effect_rev.rand_int)$tTable)
summary_season_rev.rand_int$type = 'Random Intercept'
summary_season_rev.rand_int = tibble::rownames_to_column(summary_season_rev.rand_int, "Covariates")

summary_season_rev.ar_rand_int = as.data.frame(summary(seasonal_effect_rev.ar_rand_int)$tTable)
summary_season_rev.ar_rand_int$type = 'Autoregressive Random Intercept'
summary_season_rev.ar_rand_int  = tibble::rownames_to_column(summary_season_rev.ar_rand_int, "Covariates")


summary_season_rev.rand_coef = as.data.frame(summary(seasonal_effect_rev.rand_coef)$tTable)
summary_season_rev.rand_coef$type = 'Random Slope'
summary_season_rev.rand_coef = tibble::rownames_to_column(summary_season_rev.rand_coef, "Covariates")


cols = intersect(colnames(summary_season_rev.rand_coef),colnames(summary_season_rev.ar))
cols = intersect(colnames(summary_season_rev.rand_int),cols)
cols = intersect(colnames(summary_season_rev.rand_coef),cols)

season_summary_combined = rbind(summary_season_rev.rand_coef[, cols], summary_season_rev.ar_rand_int[, cols],summary_season_rev.rand_int[, cols],summary_season_rev.ar[, cols],summary_season_rev.base[, cols])
season_summary_combined$significance <- ifelse(season_summary_combined$`p-value`<0.05, 'Significant Feature', 'Not Significant')
season_summary_combined
```
Using a 5% significance threshold, we can conclude that each of the covariates used to predict revenue had a significant impact.
```{r}
knitr::kable(season_summary_combined %>%
  group_by(Covariates) %>%
  summarise(significant = sum(significance == "Significant Feature"),
            not_significant = sum(significance == "Not Significant")),caption = 'Feature Significance (5%)')
```

The Model estimates are similar despite different correlation structures. In this sense, we can see that the size and direction of each covariate is similar across each model.

```{r}
ggplot(season_summary_combined, aes(fill=type, y=Value, x=Covariates)) + 
  geom_bar(colour="black",position='dodge', stat='identity')  + ggtitle ("Effect of LMMs on Coefficients") + theme_minimal () + theme(legend.position="bottom")
```
###Interpretation
* Intercept: This is the average revenue when all values are set at 0. In our case, it would be that for non members, in the month of April, with no rain and temperature at 0 degrees, the expected revenue is roughly -($2,500) across all the models. This number is unrealistic as Bixi revenue is a strictly positive number. It would have been more interpretable if revenue was allowed to be a negative number by accounting for cost.

* mem1: Members contribute roughly $6,000 in additional revenue for a given station compared to non-members holding other variables constant.

* mm5: Rides in the month of May contribute about $1,200 in additional revenue for a given station compared to the month of April holding all other variables constant.

* mm6: Rides in the month of June contribute about $1,250 in additional revenue for a given station compared to the month of April holding all other variables constant.

* mm7: Rides in the month of July contribute about $1,280 in additional revenue for a given station compared to the month of April holding all other variables constant.

* mm8: Rides in the month of August contribute about $1,250 in additional revenue for a given station compared to the month of April holding all other variables constant.

* mm9: Rides in the month of May contribute about $2,200 in additional revenue for a given station compared to the month of April holding all other variables constant.

* mm10: Rides in the month of May contribute about $1,000 in additional revenue for a given station compared to the month of April holding all other variables constant.

* mm11: Rides in the month of May contribute about $700 in additional revenue for a given station compared to the month of April holding all other variables constant.

* rain: A 1 unit increase in rain contributes to a $100 decrease in revenue for a given station holding all other variables constant.

* temp: A 1 unit increase in temperature contributes to a $100 increase in revenue for a given station holding all other variables constant.



Using AIC and BIC metrics, the model incorporating a random slope as well as the model incorporating an autoregressive correlation structure with a random intercept perform best when predicting revenue using season, membership and period data. This was assessed by the fact that they both have the lowest BIC and AIC metrics of all the models considered. It is also worth noting that the basic linear model that does not account for autocorrelation in the data fits the data the least optimally. 
```{r}
performance.df <- data.frame("Type"=numeric(),"AIC"=numeric(),"BIC"=numeric(),"LL"=numeric())  
performance.df[nrow(performance.df) + 1,] = c("Base",AIC(seasonal_effect_rev_model),BIC(seasonal_effect_rev_model),logLik(seasonal_effect_rev_model))

performance.df[nrow(performance.df) + 1,] = c("Autoregressive",AIC(seasonal_effect_rev.ar),BIC(seasonal_effect_rev.ar),logLik(seasonal_effect_rev.ar))

performance.df[nrow(performance.df) + 1,] = c("Autoregressive Random Intercept",AIC(seasonal_effect_rev.ar_rand_int),BIC(seasonal_effect_rev.ar_rand_int),logLik(seasonal_effect_rev.ar_rand_int))

performance.df[nrow(performance.df) + 1,] = c("Random Intercept",AIC(seasonal_effect_rev.rand_int),BIC(seasonal_effect_rev.rand_int),logLik(seasonal_effect_rev.rand_int))

performance.df[nrow(performance.df) + 1,] = c("Random Slope",AIC(seasonal_effect_rev.rand_coef),BIC(seasonal_effect_rev.rand_coef),logLik(seasonal_effect_rev.rand_coef))

knitr::kable(performance.df %>% arrange(BIC),caption='Model Performance')
```

```{r}
anova(seasonal_effect_rev.rand_coef,seasonal_effect_rev.rand_int)
```
```{r}
# Testing to see if anova command produces same result for LRT test
#D <- -2 * (seasonal_effect_rev.rand_int$logLik - seasonal_effect_rev.rand_coef$logLik)
#print(D)
#pchisq(D, df = 13, lower.tail = FALSE)/2

```
We further performed likelihood ratio tests between each of the linear mixed models and the base linear model in order to assess whether the full model fits the data significantly better than the nested model. In our analysis, the nested model consisted simply of the linear model and the full model accounted for the addition of parameters relating to the correlation structure of random effects. In each case, we concluded that the full model performed significantly better using a 1% significance threshold. This effectively means that making changes to the model structure by accounting for autocorrelation leads to a significant improvement in fit relative to a linear model.
```{r}
anova(seasonal_effect_rev.rand_int,seasonal_effect_rev_model)
anova(seasonal_effect_rev.rand_coef,seasonal_effect_rev_model)
anova(seasonal_effect_rev.ar_rand_int,seasonal_effect_rev_model)
anova(seasonal_effect_rev.ar,seasonal_effect_rev_model)
```



```{r}
getVarCov(seasonal_effect_rev.rand_coef, type = "random.effects")
```

Using information criterion and likelihood ratio tests, we compared the
4 linear mixed models together.

```{r}
anova(seasonal_effect_rev.ar, seasonal_effect_rev.ar_rand_int,seasonal_effect_rev.rand_coef,seasonal_effect_rev_gls)
AIC(seasonal_effect_rev_model)
#anova(seasonal_effect_rev_model,seasonal_effect_rev.ar)
```
```{r}
anova(seasonal_effect_rev.rand_coef,seasonal_effect_rev_gls)
```


```{r}
lrtest(seasonal_effect_rev.ar,seasonal_effect_rev.rand_coef)
```

```{r}
lrtest(seasonal_effect_rev_gls,seasonal_effect_rev.rand_coef)
```

```{r}
lrtest(seasonal_effect_rev_gls,seasonal_effect_rev.ar_rand_int)
```

```{r}
AIC(seasonal_effect_rev.ar)
```

```{r}
nobs(seasonal_effect_rev_model)
nobs(seasonal_effect_rev.ar_rand_int)
```

```{r}
#widyr::pairwise_cor(df_main, station, rain, c)
#df_main %>% select(station:rain) %>% modelsummary::datasummary_correlation()

```


# Research Question 2: How do daily and weekly patterns impact trip durations for BIXI Montréal?

**Objective of Analysis:** This regression model is examining the impact of the day of the month (`dd`), day of the week (`wday`), and holidays (`holiday`) on the revenue (`rev`) generated by trips leaving from a
specified station.

## Model

```{r Time_pattern_trip_duration, echo=FALSE}
time_pattern_dur_model_mixed <- lmer(dur ~ holiday + wknd_ind + wknd_ind*mem + (1|district/station), data=df_main)
summary(time_pattern_dur_model_mixed)

```
The model explores the relationship between trip duration (`dur`) and
factors like holidays (`holiday`), weekend indicator (`wknd_ind`),
membership status (`mem`) and its interaction with weekend indicator,
considering the nested structure of stations within districts.

**Random Effects** - **Station:District Variability**: The significant
variance in the random intercepts for stations within districts
(Variance = 23,795, Std. Dev. = 154.3) suggests considerable differences
in baseline trip durations across stations, depending on their
district. - **District-Level Variability**: There is also notable
variability between districts (Variance = 12,617, Std. Dev. = 112.3),
indicating that the district a station belongs to influences trip
duration. - These results highlight the importance of accounting for the
hierarchical structure of the data (stations nested within districts).

**Fixed Effects (Significance & Interpretation)** - **Intercept**: The
negative intercept (-34.453) may not be meaningful by itself, as it
represents the expected trip duration when all other variables are at
their reference levels. In this context, an intercept of -34.453 would
mean that when it's a non-holiday weekday, and the rider is not a
member, the model predicts a trip duration of -34.453 units. Since
negative trip duration is not possible, this result might initially seem
nonsensical. - **Holiday (significant)**: On average, holding other
variables constant, total trip durations on holidays are 51.945 minutes
longer compared to non-holidays. This reflects a tendency for longer
trips during holidays. This effect is statistically significant (p \<
0.001). - **Weekend Indicator (significant)**: On average, with other
factors held constant, total trip durations on weekends are 67.896
minutes longer than on weekdays. This indicates a preference or tendency
for longer trips during weekends. This is highly significant (p \<
0.001). - **Membership Status (significant)**: Holding other variables
at their reference levels, on average, members have a total trip
durations that are 313.065 minutes longer compared to non-members. This
might indicate different usage patterns, such as members taking longer
trips., a highly significant effect (p \< 0.001). - **Interaction:
Weekend and Membership (significant)**: On average, and with other
variables held constant, the interaction effect suggests that the
increased total trip duration associated with membership is reduced by
68.763 minutes on weekends. This indicates that the distinction in trip
duration between members and non-members is less pronounced on weekends.
This is also statistically significant (p \< 0.001).

**Correlations of Fixed Effects** - The correlation matrix shows the
relationships between the different fixed effects in the model. High
correlations can indicate potential multicollinearity issues, which
might affect the interpretation of coefficients. However, in the model,
these correlations seem relatively moderate.

**Overall Interpretation** - The model indicates that both the day of
the week (weekend vs. weekday) and membership status significantly
impact trip durations, with an interesting interaction effect on
weekends for members. - The significant random effects imply that both
the specific station and the district it's in are important factors
influencing trip durations. - The model appears to be a good fit for the
data, capturing key variability both within and between groups (stations
and districts).

```{r}
null_model <- lmer(dur ~ 1 + (1 | district/station), data = df_main)

#Compare full model to null model (refitting using mle)
anova(time_pattern_dur_model_mixed, null_model)

```

-   The significant Chi-square test (p \< 0.001) suggests that the fixed
    effects included in the full model (related to holidays, weekends,
    and membership status) contribute meaningfully to explaining the
    variability in trip durations.
-   The lower AIC and BIC values for the full model compared to the null
    model further support that the full model provides a better fit to
    the data.
-   This analysis strongly indicates that the factors of holidays,
    weekends, and membership status, along with their interactions, are
    important predictors of trip duration in the context of the
    bike-sharing data.

## Assumptions

```{r}
# Using lmer model
residuals <- residuals(time_pattern_dur_model_mixed)

# Histogram
hist(residuals, breaks=30, main="Histogram of Residuals")

# Q-Q Plot
qqnorm(residuals)
qqline(residuals)

plot(fitted(time_pattern_dur_model_mixed), residuals, xlab="Fitted Values", ylab="Residuals")
abline(h=0, col="red")


# For non-time series data
plot(residuals, type="l")

# For time series data
acf(residuals)

vif(time_pattern_dur_model_mixed)  # Note: This works if 'model' is an 'lm' object; for 'lmer' objects, you might need to adapt.

ranef_plot <- ranef(time_pattern_dur_model_mixed)
plot(ranef_plot)

predicted_values <- predict(time_pattern_dur_model_mixed)
plot(df_main$dur, predicted_values)
abline(0, 1)
 
```

**Histogram of Residuals** The histogram shows the distribution of
residuals. It suggests that the residuals are fairly symmetrically
distributed around zero, indicating that the assumption of normality
might be reasonably met. However, the distribution appears slightly
leptokurtic (having a peak higher than a normal distribution), suggested
by the tall center of the histogram.

**Normal Q-Q Plot** The Q-Q plot compares the quantiles of the residuals
to the quantiles of a normal distribution. If the residuals were
perfectly normally distributed, the points would lie on the 45-degree
reference line. In the Q-Q plot, the points deviate from the line at the
ends, indicating potential heavy tails in the distribution of residuals.
This could suggest some departure from normality, particularly with
potential outliers or extreme values.

**Residuals vs Fitted Values Plot** The residuals should be randomly
scattered around the horizontal line at zero, with no clear pattern. In
the plot, there seems to be a slight "funnel" shape, where the variance
of the residuals increases with the fitted values, which could indicate
heteroscedasticity.

**Residuals vs Index Plot** This plot displays residuals against the
observation index. It's useful for detecting patterns that may indicate
violation of independence. The residuals appear randomly scattered,
suggesting no obvious violation of independence. However, there are some
visible outliers, which should be investigated further.

**ACF Plot of Residuals** The autocorrelation function (ACF) plot is
used to check for autocorrelation in the residuals at different lags.
The bars represent correlations at different lag values. If most of them
are within the blue dashed lines (representing confidence intervals), it
suggests little to no autocorrelation. The ACF plot shows that
autocorrelation is not a concern as the correlations are within the
bounds.

**Q-Q Plot of Random Effects** This plot should show whether the random
effects are normally distributed. The random effects (intercepts for
`district/station` in the model) should fall along the reference line if
they're normally distributed. There's some deviation from normality, but
it's not extreme.

**Predicted vs Actual Values Plot** This plot compares the predicted
values from the model to the actual values. Ideally, the points should
fall around the 45-degree line, indicating good model fit. The plot
shows a reasonable alignment along the line, although it seems to
diverge for higher values, suggesting the model might not predict as
well in that range.

**Interpretation Summary** The model assumptions are not strictly
violated, but there are indications of potential issues:

-   The residuals are roughly normally distributed but show signs of
    leptokurtosis.
-   There might be some heteroscedasticity, as indicated by the
    Residuals vs Fitted Values plot.
-   There are outliers in the data that could be influential points
    worth investigating.
-   The assumption of independence seems to be met based on the
    Residuals vs Index and ACF plots.
-   The random effects may slightly deviate from normality, but not
    severely.

**Limitation of the model** Given these observations, the following
improvement could be made :

-   Transforming the response variable or using robust regression
    techniques to handle non-normality and heteroscedasticity.
-   Investigating and potentially addressing outliers.

```{r}
time_pattern_dur.ar <- gls(dur ~ dd + wday + holiday, correlation = corAR1(form = ~ 1 | station), data = df_main)

# Display model summary
summary(time_pattern_dur.ar)
```

```{r}
# holiday not working as random coefficient
# time_pattern_dur.rand_coef <- lme(dur ~ dd + wday + holiday, random = ~1 + dd |
# station, data = df_main)
# summary(time_pattern_dur.rand_coef)

## Does not converges...
```

## Business interpretation

From a business perspective, the findings from this analysis offer
valuable insights for strategic planning, marketing, operational
adjustments, and potential policy development. Here are the main
takeaways:

**Holidays and Weekends promotion** The model indicates longer trip
durations during holidays and weekends. This suggests higher usage or
leisurely rides during these periods. There could be an opportunity to
increase bike availability or introduce special promotions during
holidays and weekends to cater to this demand. The interaction effect
suggests that members' increased trip duration is less pronounced on
weekends. This could imply that members use the service differently on
weekends compared to weekdays. Design weekend-specific promotions or
services for members. Understanding why this pattern occurs (leisure vs.
commuting) can help tailor these offerings.

**Membership pricing strategy** Members tend to have significantly
longer trip durations compared to non-members. This highlights the
importance of members to the system. There should have a focus on member
retention strategies and consider special offers or loyalty programs to
encourage repeat usage. Additionally, analyzing non-member behavior to
tailor services and promotions effectively would be pertinent.

**Geographic optimization** Significant variability in trip durations
across different stations and districts indicates diverse usage patterns
in different areas. Optimize bike and dock availability based on
specific district and station demands. Targeted investments in
high-usage areas could improve service efficiency.

**Potential Policy Implications** Understanding how different areas and
demographics use the bike-sharing system can inform urban planning and
public transport policies. Promoting bike-sharing effectively can
contribute to environmental goals by reducing reliance on motorized
transportation. \# Research Question 3: What variables impact the
average bixi trip duration?

**The objective** is to identify the driving factors of a bixi's trip
length when we control for most of the variables. Trip length is one of
the three important variables that drives revenue, the other ones being
the number of trips and the pricing scheme. Keep in mind that increasing
the trip length does not necessarily increase revenues since an unwanted
increase in trip length may discourage users from using bixi's system
and result in a decrease in trip number.

## Variables Selection


REMOVE PART OF MONTH Our goal is to incorporate most of the important
variables in order to increase our chance of respecting the assumption
of E(e)=0 and thus making our model more telling.

Variables that make business sense to include:

From our seasonality analysis we identified:

-   Season; grouping of months from april to november in their
    respective season (`season`)

-   Temperature in degrees celcius (`temp`)

-   Rainfall in mm (`rain`)

From our daily and weekly pattern analysis we identified:

-   Part of the week i.e. weekend or weekday (`wknd_ind`)

-   If it is a holiday (`holiday`)

Some other variables that are interesting:

-   If the user is a member(`mem`)

-   Location of the bixi station compared to Parc Lafontaine, a landmark
    in the middle of the bixi station system (`cardinality`)

-   Proportion of trips in the morning versus the whole day
    (`percent_AM`)

-   If the station name contains the word 'metro' (`Metro_ind`)


**Interactions**: In our EDA we observed a different week day usage of
the member and non members, thus an interaction term between members and
day of week would be interesting. (`wday*mem`).

**Correlation:**

Let's take a quick look at the correlation between our numerical
variables to estimate the effect of collinearity.

```{r , echo=FALSE}
cor(df_main[c('avg', 'temp', 'rain', 'n_tot', 'percent_AM')])
```

We see very low correlation between the Xs which means we should not get
any problems with collinearity between our numerical variables.



## Model

head(df_main)

df_main %>%
  count(station, sort = TRUE)

Benchmark model

```{r , echo=FALSE}
model_AvgDur_0 <- lm(avg ~ season + temp + rain + wknd_ind*mem + holiday  + cardinality + percent_AM  + Metro_ind, data = df_main)
summary(model_AvgDur_0)
```

Model with unstructured covariance matrix

```{r , echo=FALSE}
# start_date = min(df_main$date)
# df_main$day_num = as.integer(df_main$date - start_date)
# 
# 
# model_AvgDur_1 <- gls(avg ~ season + temp + rain + wknd_ind*mem + holiday  + cardinality + percent_AM  + Metro_ind, correlation= corSymm(form=~1|station), weights = varIdent(form = ~1 | day_num), data = df_main)
# summary(model_AvgDur_1)
# 
# 
# 
# 
# 
# model_arh1 <- gls(avg ~ season + temp + rain+ day_num + wknd_ind*mem + holiday  + cardinality + percent_AM  + Metro_ind, correlation = corAR1(form = ~ day_num | station), data = df_main)
# 
# 
# mod1 <- gls(avg ~ season + temp + rain+ day_num + wknd_ind*mem + holiday  + cardinality + percent_AM  + Metro_ind, correlation = corCompSymm(form = ~1 |
# station), data = df_main)
# summary(mod1)
# 
# 
# getVarCov(mod1, individual = 2)
# 
# 
# mod2 <- gls(avg ~ season + temp + rain+ day_num + wknd_ind*mem + holiday  + cardinality + percent_AM  + Metro_ind, correlation = corAR1(form = ~day_num |station/mem), data = df_main)
# summary(mod2)
# 
# getVarCov(mod2, individual = 1)
# 
# 
# df_main %>%
#   group_by(station, dd,mm,mem) %>%
#   summarise(n = n()) %>%
#   filter(n > 1) 
# 
# df_main[(df_main$dd == 8) & (df_main$mm== 5)& (df_main$station == 21),]
# 
```

## Interpretation

**Overall Model** - The model explains approximately 10% of the
variation in the average trip duration which means that other factors
are also at play and are not included in the model. The p value
associated with the F-statistic is very low, hence our model is globally
significant.

**Intercept** : The interpretation of the intercept does not make sense
in this case

**Season**: The reference level is fall. We can see that on average trip
duration during spring and summer are respectively 2.7 and 0.5 minutes
longer than in fall holding everything else constant.

**Temperature**: The coefficient of temperature is 0.11 which means that
an increase in temperature of 1 degree celcius corresponds to an
increase of average trip duration of 0.11 minutes on average holding all
else constant.

**Rainfall**: The coefficient for rain is -0.1 which means that an
increase in rainfall of 1 mm corresponds to a decrease of average trip
duration of 0.1 minutes on average holding all else constant.

**Effect of Weekend Indicator and membership**: Since there exists an
interaction between both variables, it is no longer possible to
interpret one without the other. This implies that the relation between
average trip duration and membership is different depending on the
moment of the week. The opposite is also true, the relation between
average trip duration and the moment of the week is different depending
on the membership status. We observe that non-member have longer trips
on average and that weekend trips tends to increase average trip length.

The 4 different levels in order of trip length are as follows: EXPLAIN
IN WORDS 1. Lowest level : Weekday and member (-1.84 minutes)

2.  Second lowest : Weekend and member (2.5-1.8-1.5 = -0.8 minutes)

3.  Reference level: Weekday and non-member (0 minutes)

4.  Highest level : weekend and non-member (+2.47 minutes)

**Holiday**: The coefficient for holiday is 1.06 which means that during
holidays average trip duration is 1.06 minutes higher on average than
during non-holidays, holding all else constant.

**North_South and West_East**: Their coefficients are 0.08 and -0.26
which means that on average the average trip duration for trips starting
at a station South of Parc Lafontaine or West is 0.08 and -0.26 minutes
different from their counter parts respectively, holding all else
constant. Keep in mind that the coefficient for North_South is not
significantly different from zero

**Percent AM**: The magnitude of the coefficient -2.03 is less important
than its sign for our interpretation. What it means is that as the
proportion of trips in the morning increases, the average trip duration
generally decreases when holding all else constant. This hints that
trips in the morning might be shorter on average than trip in the
afternoon, hence bring in less revenue.

**Part of Month** : The coefficient for part of month is -0.22 which
means that on average, the average trip duration is 0.22 minutes shorter
in the second half of the month holding all else constant. This feature
was not found to be significantly different from zero.

**Metro Indicator** : Metro indicator's coefficient is -0.75 which means
that the expected value for average trip length decreases by 0.75
minutes when a bixi station is near a metro acces point, holding all
else constant. This would suggest that user who rent bikes after making
a metro ride are closer to their final destination than in other cases.

## Business Implications:

1.  **Promotion and Marketing**: For the same temperature, average trip
    length tends to be the longest in spring. This indicates that users
    are eager to use bikes after winter. This insight could be used for
    promotion purposes.

2.  **Resource Allocation**: Expect longer trips when it is hot and
    non-rainy outside. Even more if it is a weekend or holiday. Also,
    bikes tend to be borrowed longer during the afternoon than in the
    morning. Stations south of Parc Lafontaine have on average longer
    trip duration, which may suggests that stations are further from one
    another. There might be some space for additional stations.

3.  **Pricing Strategy**: The usage that is associated with the longest
    trip length based on our interaction term is for non-members during
    the weekend. Charging a heftier price for these people at that time
    may increase profit margins significantly.

## Verification of assumptions and collinearity

### Variance Inflation Factor

Let's use the variance inflation factor to verify for collinearity, we
will use a standard threshold of 5.

```{r , echo=FALSE}
# vif(model_AvgDur)
```

No major problem is detected, since the global vifs are all relatively
low.

### Verification of Normality of Residuals

```{r, echo=FALSE, fig.width=4, fig.height=3}
# #pin=c(2,2)
# res = hist(model_AvgDur$residuals, main="Histogram of Residuals", xlab="Residuals")
# 
```

No problem here, residuals are normally distributed.

### Model correctly specified

```{r , echo=FALSE, fig.width=4.5, fig.height=3.5}
# plot(predict(model_AvgDur), resid(model_AvgDur)) 
```

The model seems to be correctly specified.

### Verificaiton of Heteroscedasticity

```{r , echo=FALSE}

# residuals_df <- data.frame(df_main, residuals = residuals(model_AvgDur))
# 
# p1 <- ggplot(data = residuals_df, aes(x = temp, y = residuals)) +
#   geom_point() +
#   labs(x = "temp", y = "Residuals")
# 
# p2 <- ggplot(data = residuals_df, aes(x = rain, y = residuals)) +
#   geom_point() +
#   labs(x = "rain", y = "Residuals")
# 
# p3 <- ggplot(data = residuals_df, aes(x = n_tot, y = residuals)) +
#   geom_point() +
#   labs(x = "n_tot", y = "Residuals")
# 
# p4 <- ggplot(data = residuals_df, aes(x = percent_AM, y = residuals)) +
#   geom_point() +
#   labs(x = "percent_AM", y = "Residuals")
# 
# p5 <- ggplot(data = residuals_df, aes(x = season, y = residuals)) + geom_boxplot() +
#   labs(x = "season", y = "Residuals")
# 
# p6 <- ggplot(data = residuals_df, aes(x = mem, y = residuals)) + geom_boxplot() +
#   labs(x = "mem", y = "Residuals")
# 
# p7 <- ggplot(data = residuals_df, aes(x = holiday, y = residuals)) + geom_boxplot() +
#   labs(x = "holiday", y = "Residuals")
# 
# p8 <- ggplot(data = residuals_df, aes(x = North_South, y = residuals)) + geom_boxplot() +
#   labs(x = "North_South", y = "Residuals")
# 
# p9 <- ggplot(data = residuals_df, aes(x = West_East, y = residuals)) + geom_boxplot() +
#   labs(x = "West_East", y = "Residuals")
# 
# p10 <- ggplot(data = residuals_df, aes(x = PartOfMonth, y = residuals)) + geom_boxplot() + labs(x = "PartOfMonth", y = "Residuals")
# 
# p11 <- ggplot(data = residuals_df, aes(x = Metro_ind, y = residuals)) + geom_boxplot() + labs(x = "Metro_ind", y = "Residuals")
# 
# grid.arrange(p1, p2, p4, p5, p6, p7, p8, p9, p10, p11, ncol=3)

```

No major problem of heteroscedasticity were detected. The variable
`n_tot` has been removed as stated earlier.

# Limitations and shortcomings

-   Causation vs. Correlation: The regression model captures
    relationships but does not establish causation.
-   Data Exclusions: The data only considers trips under 60 minutes,
    which might exclude a segment of users who use BIXI for longer
    journeys.
-   Other External Factors: Events, road conditions, or public
    transportation disruptions can affect BIXI usage but are not
    captured in the dataset.

# Conclusion

In conclusion, several key operational and strategic considerations have
emerged from the data analysis of BIXI bike rentals:

Operational Adjustments: The data suggests that revenue is higher in
warmer months. To capitalize on this, it is advisable to optimize
operations during this period, which could involve increasing staffing,
enhancing promotional activities, and ensuring optimal equipment
availability.

Rainy Day Strategies: Rainfall appears to have a negative impact on
revenue. Implementing strategies to mitigate this effect, such as
promotional offers or special activities for rainy days, may help
attract more customers.

Promotion and Marketing: Data indicates that average trip length is
longest in spring, suggesting an eagerness to use bikes after winter.
This insight can be leveraged for promotional purposes.

Resource Allocation: Understanding patterns in trip duration based on
weather, time of day, and location is crucial for resource allocation.
Longer trips are expected during hot, non-rainy weekends and holidays.
Stations in certain areas have longer trip durations, indicating
potential for additional station placement.

Pricing Strategy: The analysis highlights that non-members on weekends
tend to take longer trips. Adjusting pricing for this group during these
times could significantly increase profit margins.

Operational Strategy: It's important to consider the tradeoff between
the number of trips and average trip length. Increasing the number of
trips on a given day may lead to shorter hauls. This information should
inform operational decisions. Incorporating these insights into the
business's operations and strategies can lead to improved efficiency,
customer satisfaction, and profitability

# Contribution

Charles Julien :Research question 3, version control, part of feature
engineering, formating.

Gabriel Jobert : Research question 1 and 2

Chike Odenigbo: exploratory models (not included), feature engineering,
influential observations, autocorrelation

Atul Sharma: Contributed in developing the Reseacrh questions,
interpreting the findings of the model and finalising the conclusion .
